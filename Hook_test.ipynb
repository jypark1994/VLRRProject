{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597366883638",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HookWrapper(nn.Module):\n",
    "    '''\n",
    "        Wrapper class for Forward/Backward feature map extraction.\n",
    "\n",
    "        - Usage -\n",
    "        1) Make the instance of this class with the model and target layers.\n",
    "        2) Forward/Backward it.\n",
    "        3) Call get_features() will return the feature maps of previously forward/backwarded input.\n",
    "        4) Back to 2).\n",
    "    '''\n",
    "    def __init__(self, model, target_layers):\n",
    "        super(HookWrapper,self).__init__()\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.features = [] # Size will be 4 after hook\n",
    "\n",
    "        for name, module in model.named_children():\n",
    "            if name in target_layers:\n",
    "                module.register_forward_hook(self._extraction_fn)\n",
    "\n",
    "    def _extraction_fn(self, module, input, output):\n",
    "        # print(f\"Test : {output.shape}\")\n",
    "        self.features.append(output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def get_features(self): # Return feature list and make it empty.\n",
    "        tmp = self.features\n",
    "        self.features = []\n",
    "        return tmp\n",
    "\n",
    "target_layers = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "net_t = models.resnet18(pretrained=True)\n",
    "net_s = models.resnet18(pretrained=True)\n",
    "hook_net_t = HookWrapper(net_t, target_layers)\n",
    "hook_net_s = HookWrapper(net_s, target_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<zip object at 0x7febbacf8c30>\ntorch.Size([1, 64, 28, 28]) torch.Size([1, 64, 28, 28])\n-- Loss : 0.81485515832901\ntorch.Size([1, 128, 14, 14]) torch.Size([1, 128, 14, 14])\n-- Loss : 0.23540174961090088\ntorch.Size([1, 256, 7, 7]) torch.Size([1, 256, 7, 7])\n-- Loss : 0.11088081449270248\n"
    }
   ],
   "source": [
    "x_HR = torch.randn((1,3,224,224))\n",
    "x_LR = torch.randn((1,3,112,112))\n",
    "pred_t = hook_net_t(x_HR)\n",
    "pred_s = hook_net_s(x_LR)\n",
    "\n",
    "features_t = hook_net_t.get_features()\n",
    "features_s = hook_net_s.get_features()\n",
    "\n",
    "transfer = nn.MaxPool2d(kernel_size=2, )\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(zip(features_t, features_s))\n",
    "\n",
    "for f_t, f_s in zip(features_t, features_s):\n",
    "    f_t = transfer(f_t) # Transfer function of f_t -> f_s domain.\n",
    "    if(f_t.shape != f_s.shape):\n",
    "        continue\n",
    "    print(f_t.shape, f_s.shape)\n",
    "\n",
    "    loss = criterion(f_t, f_s)\n",
    "    print(f\"-- Loss : {loss}\")"
   ]
  }
 ]
}