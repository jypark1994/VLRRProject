{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600053889357",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import models_cifar\n",
    "\n",
    "class ResNetWrapper(nn.Module):\n",
    "    '''\n",
    "        ResNet model wrapper for pytorch's official implementation\n",
    "        - Classifying ImageNet-sized(224x224x3) images.\n",
    "        Junyoung Park : jy_park@inu.ac.kr\n",
    "    '''\n",
    "    def __init__(self, net, n_classes, mode='imagenet', pretrained_weight=None):\n",
    "        super(ResNetWrapper, self).__init__()\n",
    "        self.net = net\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        if mode.lower() == 'imagenet':\n",
    "            print(\"Wrapper mode : ResNet-ImageNet\")\n",
    "            if self.n_classes != self.net.fc.out_features:\n",
    "                print(f\"- Out channels : {n_classes}\")\n",
    "                self.net.fc = nn.Linear(self.net.fc.in_features, n_classes)\n",
    "            self._forward = self._forward_imagenet # Use net.fc as FC\n",
    "\n",
    "        else: # if mode == cifar\n",
    "            print(\"Wrapper mode : ResNet-CIFAR\")\n",
    "            if self.n_classes != self.net.linear.out_features:\n",
    "                print(f\"- Out channels : {n_classes}\")\n",
    "                self.net.linear = nn.Linear(self.net.linear.in_features, n_classes)\n",
    "            self._forward = self._forward_cifar # Use net.linear as FC\n",
    "\n",
    "        if pretrained_weight != None:\n",
    "            self._load_pretrained_weight(pretrained_weight)\n",
    "\n",
    "    def _load_pretrained_weight(self, w_p):\n",
    "        state_dict = torch.load(w_p)\n",
    "        print(\"Load state dict with accuracy : {state_dict['acc']*100:.2f}%\")\n",
    "        print(\"- Weight dir : {w_p}\")\n",
    "        self.net.load_state_dict(state_dict['net'])\n",
    "\n",
    "    def _forward_cifar(self, x):\n",
    "        C1 = F.relu(self.net.bn1(self.net.conv1(x)))\n",
    "        L1 = self.net.layer1(C1)\n",
    "        L2 = self.net.layer2(L1)\n",
    "        L3 = self.net.layer3(L2)\n",
    "        L4 = self.net.layer4(L3)\n",
    "        f = F.avg_pool2d(L4, 4)\n",
    "        f = f.view(f.size(0), -1)\n",
    "        out = self.net.linear(f)\n",
    "        return (C1, L1, L2, L3, L4), out\n",
    "\n",
    "    def _forward_imagenet(self, x):\n",
    "        C1 = self.net.relu(self.net.bn1(self.net.conv1(x)))\n",
    "        C1_p = self.net.maxpool(C1)\n",
    "        L1 = self.net.layer1(C1_p)\n",
    "        L2 = self.net.layer2(L1)\n",
    "        L3 = self.net.layer3(L2)\n",
    "        L4 = self.net.layer4(L3)\n",
    "        f = self.net.avgpool(L4)\n",
    "        f = torch.flatten(f, 1)\n",
    "        out = self.net.fc(f)\n",
    "        return (C1, L1, L2, L3, L4), out\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on ImageNet-size input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wrapper mode : ResNet-ImageNet\nWrapper mode : ResNet-ImageNet\ntensor(2.9100, grad_fn=<DivBackward0>)\n"
    }
   ],
   "source": [
    "net_t = models.resnet34(pretrained=True)\n",
    "net_s = models.resnet34(pretrained=False)\n",
    "\n",
    "net_t = ResNetWrapper(net_t, 1000, mode='imagenet')\n",
    "net_s = ResNetWrapper(net_s, 1000, mode='imagenet')\n",
    "x = torch.randn([1,3,224,224])\n",
    "y_t = net_t(x)\n",
    "y_s = net_s(x)\n",
    "\n",
    "# [0][4] : Final Conv Layer.\n",
    "features_t, pred_t = y_t[0][4], y_t[1]\n",
    "features_s, pred_s = y_s[0][4], y_s[1]\n",
    "\n",
    "loss = 0\n",
    "\n",
    "for f_t, f_s in zip(features_t, features_s):\n",
    "    loss += nn.MSELoss()(f_t,f_s)\n",
    "\n",
    "print(loss/len(features_t))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on CIFAR-size input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wrapper mode : ResNet-CIFAR\nWrapper mode : ResNet-CIFAR\ntensor(2.6612, grad_fn=<DivBackward0>)\n"
    }
   ],
   "source": [
    "net_t = models_cifar.ResNet34()\n",
    "net_s = models_cifar.ResNet34()\n",
    "\n",
    "net_t = ResNetWrapper(net_t, 10, mode='cifar')\n",
    "net_s = ResNetWrapper(net_s, 10, mode='cifar')\n",
    "x = torch.randn([1,3,32,32])\n",
    "y_t = net_t(x)\n",
    "y_s = net_s(x)\n",
    "\n",
    "# [0][4] : Final Conv Layer.\n",
    "features_t, pred_t = y_t[0][4], y_t[1]\n",
    "features_s, pred_s = y_s[0][4], y_s[1]\n",
    "\n",
    "loss = 0\n",
    "\n",
    "for f_t, f_s in zip(features_t, features_s):\n",
    "    loss += nn.MSELoss()(f_t,f_s)\n",
    "\n",
    "print(loss/len(features_t))\n",
    "\n"
   ]
  }
 ]
}